{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common plotting issues that get worse with large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Requires holoviews, which can be installed with \"conda install -c ioam holoviews\"\n",
    "import holoviews as hv\n",
    "hv.notebook_extension()\n",
    "hv.archive.auto(exporters=[hv.Store.renderers['matplotlib'].instance(size=50, fig='png', dpi=144)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%opts Points [color_index=2] (cmap=\"bwr\" edgecolors='k' s=50 alpha=1.0)\n",
    "%opts Scatter3D [color_index=3 fig_size=250] (cmap='bwr' edgecolor='k' s=50 alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overplotting\n",
    "\n",
    "Let's consider plotting data that comes from two categories, here plotted in blue and red as A and B below.  When the two categories are overlaid, the result can be very different depending on which one is plotted first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "blue_coords = (np.random.normal( 0.5,size=300), np.random.normal( 0.5,size=300))\n",
    "red_coords  = (np.random.normal(-0.5,size=300), np.random.normal(-0.5,size=300))\n",
    "\n",
    "blues = hv.Points(blue_coords + (-1,), vdims=['c'])\n",
    "reds  = hv.Points(red_coords  + ( 1,), vdims=['c'])\n",
    "\n",
    "quartet = (blues + reds + reds*blues + blues*reds).cols(2)\n",
    "quartet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots C and D shown the same distribution of points, yet they give a very different impression of which category is more common, which can lead to incorrect decisions based on this data.  Actually, both are equally common in this case.  The cause for this problem is simply occlusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hmap = hv.HoloMap({0:blues,0.000001:reds,1:blues,2:reds}, key_dimensions=['level'])\n",
    "hv.Table(hmap.table(), kdims=['x','y','level'], vdims=['c']).to.scatter3d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occlusion of data by other data is called **overplotting** or **overdrawing**, and it occurs whenever a datapoint is plotted on top of another datapoint, obscuring it.\n",
    "\n",
    "\n",
    "## Saturation\n",
    "\n",
    "You can reduce problems with overplotting by using transparency, via the alpha parameter provided in most plotting programs.  E.g. if alpha is 0.1, full brightness will be achieved only when 10 points overlap, reducing the effects of plot ordering but making it harder to see individual points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Points (s=50 alpha=0.1)\n",
    "quartet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here C and D look fairly similar (as they should, since the distributions are identical), but there are still a few locations that have reached **saturation**, a problem that will occur when more than 10 points overlap.  With multiple categories as here, saturation leads to overplotting problems, because only the last 10 points plotted will affect the final color.  With a single category, saturation simply obscures differences in density.  For instance, 10, 20, and 2000 points overlapping will all look the same visually, for alpha=0.1.\n",
    "\n",
    "The biggest problem with using alpha to avoid saturation is that the correct value depends on the dataset -- e.g. if there are more points overlapping, a manually adjusted alpha setting that worked well for a previous dataset will systematically misrepresent the new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Points (s=50 alpha=0.1)\n",
    "\n",
    "np.random.seed(42)\n",
    "blue_coords = (np.random.normal( 0.5,size=900), np.random.normal( 0.5,size=900))\n",
    "red_coords  = (np.random.normal(-0.5,size=900), np.random.normal(-0.5,size=900))\n",
    "\n",
    "blues = hv.Points(blue_coords + (-1,), vdims=['c'])\n",
    "reds  = hv.Points(red_coords  + ( 1,), vdims=['c'])\n",
    "\n",
    "(blues + reds + reds*blues + blues*reds).cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here C and D again look very different, yet represent the same distributions.  The correct alpha also depends on the dot size, because that affects the amount of overlap. With smaller dots, C and D look more similar, but the dots are now difficult to see because they are too transparent for this size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Points (s=10 alpha=0.1 edgecolor=None)\n",
    "quartet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is difficult to find settings for the dotsize and alpha parameters that correctly reveal the data, even for relatively small and obvious datasets like these.  With larger datasets, it is difficult to detect that such problems are occuring, leading to false conclusions based on inappropriately visualized data.\n",
    "\n",
    "## Binning problems\n",
    "\n",
    "For large enough datasets, plotting every point as above is not always practical.  2D histograms visualized as heatmaps offer a practical way to visualized data compactly, and can also address issues like saturation directly (by effectively auto-ranging the alpha parameter based on the bin with the highest count).  Heatmaps can approximate a probability density function, averaging out noise or irrelevant variations to reveal an underlying distribution.\n",
    "\n",
    "Here, let's consider a sum of two normal distributions slightly offset from each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Image.Blues (cmap=\"Blues\") Image.Reds (cmap=\"Reds\") Image (cmap=\"Blues\") Image {+axiswise} Points (s=2)\n",
    "\n",
    "num=600\n",
    "np.random.seed(42)\n",
    "offset=1.5\n",
    "blue_coords = (np.random.normal( offset,size=num), np.random.normal( offset*0,size=num))\n",
    "red_coords  = (np.random.normal(-offset,size=num), np.random.normal(-offset*0,size=num))\n",
    "merged = (np.hstack((blue_coords[0],red_coords[0])),np.hstack((blue_coords[1],red_coords[1])))\n",
    "\n",
    "def heatmap(coords,bins=10):\n",
    "    hist= np.histogram2d(coords[0], coords[1], bins=bins)\n",
    "    return hv.Image(hist[0][:,::-1].T)\n",
    "\n",
    "(hv.Points(merged) + [heatmap(merged,bins) for bins in [8,10,20,100,1000]]).cols(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv.archive.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the distribution looks very different depending on the number of bins used -- at some heatmap resolutions, the two underlying groups can be distinguished, but in others the shape is unclear. In plot F the data is only dimly visible at all, due to the small pixel-sized bins that make multiple counts per bin unlikely.  In F nearly all the bins look like they are empty, but in fact there are many non-empty bins, they just happen to have fewer dots than a few other random bins with high overlap between datapoints.  This **undersaturation** problem, where values falsely appear to be zero because of plotting parameter settings, can hide data just as seriously as **oversaturation**, leading to incorrect conclusions about the shape of the data.\n",
    "\n",
    "Clearly, the bin size is now an important parameter that needs manual adjustment.  Yet for truly large data, there's not usually any plot like A available where all datapoints can be seen -- how do you know when your bin size is appropriate for a given dataset?  Usually the answer is \"trial and error\", which is awkward and time consuming for large data.  The result is...\n",
    "\n",
    "## For big data, you don't know when the viz is lying\n",
    "\n",
    "I.e., visualization is supposed to help you explore and understand your data, but if your visualizations are systematically misrepresenting your data because of overplotting, saturation, undersaturation, and inappropriate binning, then you won't be able to discover the real qualities of your data and will be unable to make the right decisions.\n",
    "\n",
    "The [`datashader`](https://github.com/bokeh/datashader) library has been designed to overcome many of the above problems, by automatically calculating appropriate parameters based on the data itself, and by allowing interactive visualizations of even truly large datasets with millions or billions of data points so that their structure can be revealed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
